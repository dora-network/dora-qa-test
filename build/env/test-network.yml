networks:
  default:
    external: true
    name: ${DEV_NETWORK_NAME}

services:
  kafka-1:
    image: ${DEV_KAFKA_IMAGE}
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: "LISTENER_CONTROLLER:PLAINTEXT,LISTENER_DOCKER_INTERNAL:PLAINTEXT,LISTENER_DOCKER_EXTERNAL:PLAINTEXT"
      KAFKA_ADVERTISED_LISTENERS: "LISTENER_DOCKER_INTERNAL://kafka-1:29092,LISTENER_DOCKER_EXTERNAL://${DOCKER_HOST_IP:-127.0.0.1}:9092"
      KAFKA_PROCESS_ROLES: "broker,controller"
      KAFKA_CONTROLLER_QUORUM_VOTERS: "1@kafka-1:29093"
      KAFKA_LISTENERS: "LISTENER_CONTROLLER://kafka-1:29093,LISTENER_DOCKER_INTERNAL://kafka-1:29092,LISTENER_DOCKER_EXTERNAL://kafka-1:9092"
      KAFKA_CONTROLLER_LISTENER_NAMES: "LISTENER_CONTROLLER"
      KAFKA_INTER_BROKER_LISTENER_NAME: "LISTENER_DOCKER_INTERNAL"
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_LOG_DIRS: "/tmp/kraft-combined-logs"
      # To generate a new random cluster id, run the following command: "docker run --rm confluentinc/cp-kafka:latest kafka-storage random-uuid"
      CLUSTER_ID: "Z5yBrytUTuOlc3n2JxYUww"
    #      KAFKA_ZOOKEEPER_CONNECT: "zookeeper-1:2181"
    ports:
      - "9092:9092"
      - "9101:9101"
    networks:
      - default
    restart: on-failure
  kafka-setup:
    image: ${DEV_KAFKA_IMAGE}
    hostname: kafka-setup
    depends_on:
      - kafka-1
    # The following command executes the Confluent Platform Utility Belt (cub) to wait for kafka to be ready
    # Then executes the kafka-topic command to create the topics we want for our development purposes.
    # The cub command runs the kafka-ready utility to check the required number of brokers are ready.
    # The command below passes the -b option to the kafka-ready utility along with the list of bootstrap brokers
    # followed by 2 positional arguments. The first being the number of brokers we need to be ready, the second being
    # the number of seconds we wait before timing out.
    command: "bash -c 'echo Waiting for Kafka to be ready... && \
      cub kafka-ready -b kafka-1:29092 1 60 && \
      kafka-topics --create --if-not-exists --bootstrap-server kafka-1:29092 --partitions 1 --replication-factor 1 --topic incoming_prices && \
      echo Kafka is ready'"
    environment:
      # The following settings are listed here only to satisfy the image's requirements.
      # We override the image's `command` anyways, hence this container will not start a broker.
      KAFKA_BROKER_ID: ignored
      KAFKA_ZOOKEEPER_CONNECT: ignored
    networks:
      - default
  # The Schema Registry is a separate service that we can use to store and retrieve protobuf schemas.
  redis:
    image: redis:latest
    networks:
      - default
    ports:
      - "6379:6379"
  spanner:
    image: gcr.io/cloud-spanner-emulator/emulator:latest
    ports:
      - "9010:9010"
      - "9020:9020"
      - "9030:9030"
    networks:
      - default
